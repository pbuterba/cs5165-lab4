{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, month, when\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "spark = SparkSession.builder.master('local').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = []\n",
    "for data_year in range(2015, 2025):\n",
    "    file_path = f'data/{data_year}/72429793812.csv'\n",
    "    if os.path.exists(file_path):\n",
    "        input_files.append(file_path)\n",
    "    file_path = f'data/{data_year}/99495199999.csv'\n",
    "    if os.path.exists(file_path):\n",
    "        input_files.append(file_path)\n",
    "\n",
    "csv_df = spark.read.csv(input_files, sep=\",\", header=True)\n",
    "csv_df = csv_df.withColumn('YEAR', year(col('DATE')))\n",
    "csv_df = csv_df.withColumn('MONTH', month(col('DATE')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----+-----------+\n",
      "|    STATION|            LOCATION|YEAR|NUM_ENTRIES|\n",
      "+-----------+--------------------+----+-----------+\n",
      "|72429793812|CINCINNATI MUNICI...|2015|        365|\n",
      "|99495199999|SEBASTIAN INLET S...|2015|        355|\n",
      "|72429793812|CINCINNATI MUNICI...|2016|        366|\n",
      "|72429793812|CINCINNATI MUNICI...|2017|        365|\n",
      "|99495199999|SEBASTIAN INLET S...|2017|        283|\n",
      "|72429793812|CINCINNATI MUNICI...|2018|        365|\n",
      "|99495199999|SEBASTIAN INLET S...|2018|        363|\n",
      "|72429793812|CINCINNATI MUNICI...|2019|        365|\n",
      "|99495199999|SEBASTIAN INLET S...|2019|        345|\n",
      "|72429793812|CINCINNATI MUNICI...|2020|        366|\n",
      "|99495199999|SEBASTIAN INLET S...|2020|        365|\n",
      "|72429793812|CINCINNATI MUNICI...|2021|        365|\n",
      "|99495199999|SEBASTIAN INLET S...|2021|        104|\n",
      "|72429793812|CINCINNATI MUNICI...|2022|        365|\n",
      "|99495199999|SEBASTIAN INLET S...|2022|        259|\n",
      "|72429793812|CINCINNATI MUNICI...|2023|        365|\n",
      "|99495199999|SEBASTIAN INLET S...|2023|        276|\n",
      "|72429793812|CINCINNATI MUNICI...|2024|        366|\n",
      "|99495199999|SEBASTIAN INLET S...|2024|        133|\n",
      "+-----------+--------------------+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.createOrReplaceTempView(\"WEATHER_DATA\")\n",
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        WEATHER_DATA.STATION,\n",
    "        WEATHER_DATA.NAME AS LOCATION,\n",
    "        WEATHER_DATA.YEAR,\n",
    "        COUNT(WEATHER_DATA.TEMP) AS NUM_ENTRIES\n",
    "    FROM WEATHER_DATA\n",
    "    GROUP BY WEATHER_DATA.YEAR, WEATHER_DATA.NAME, WEATHER_DATA.STATION\n",
    "    ORDER BY WEATHER_DATA.YEAR, WEATHER_DATA.STATION\n",
    "\"\"\")\n",
    "queried_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+--------+\n",
      "|    STATION|            LOCATION|      DATE|MAX_TEMP|\n",
      "+-----------+--------------------+----------+--------+\n",
      "|72429793812|CINCINNATI MUNICI...|2015-06-12|    91.9|\n",
      "|72429793812|CINCINNATI MUNICI...|2016-07-24|    93.9|\n",
      "|72429793812|CINCINNATI MUNICI...|2017-07-22|    91.9|\n",
      "|72429793812|CINCINNATI MUNICI...|2018-07-04|    96.1|\n",
      "|72429793812|CINCINNATI MUNICI...|2019-09-30|    95.0|\n",
      "|72429793812|CINCINNATI MUNICI...|2020-07-05|    93.9|\n",
      "|72429793812|CINCINNATI MUNICI...|2021-08-12|    95.0|\n",
      "|72429793812|CINCINNATI MUNICI...|2022-06-14|    96.1|\n",
      "|72429793812|CINCINNATI MUNICI...|2023-08-23|    96.1|\n",
      "|72429793812|CINCINNATI MUNICI...|2024-08-30|   100.9|\n",
      "+-----------+--------------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.filter(csv_df.MAX != 9999.9).createOrReplaceTempView(\"WEATHER_DATA\")\n",
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        STATION,\n",
    "        LOCATION,\n",
    "        DATE,\n",
    "        MAX_TEMP\n",
    "    FROM (\n",
    "        SELECT\n",
    "            WEATHER_DATA.STATION,\n",
    "            WEATHER_DATA.NAME AS LOCATION,\n",
    "            WEATHER_DATA.DATE,\n",
    "            WEATHER_DATA.MAX AS MAX_TEMP,\n",
    "            ROW_NUMBER() OVER (PARTITION BY WEATHER_DATA.YEAR ORDER BY WEATHER_DATA.MAX DESC) AS ranked_order\n",
    "        FROM WEATHER_DATA\n",
    "    ) AS max_temps\n",
    "    WHERE max_temps.ranked_order = 1\n",
    "\"\"\")\n",
    "queried_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+--------+\n",
      "|    STATION|            LOCATION|      DATE|MIN_TEMP|\n",
      "+-----------+--------------------+----------+--------+\n",
      "|72429793812|CINCINNATI MUNICI...|2015-03-06|     3.2|\n",
      "+-----------+--------------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.filter(csv_df.MIN != 9999.9).createOrReplaceTempView(\"WEATHER_DATA\")\n",
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        STATION,\n",
    "        NAME AS LOCATION,\n",
    "        DATE,\n",
    "        MIN AS MIN_TEMP\n",
    "    FROM WEATHER_DATA\n",
    "    INNER JOIN (\n",
    "        SELECT\n",
    "            MIN(MIN) AS MIN_TEMP\n",
    "        FROM WEATHER_DATA\n",
    "        WHERE MONTH = 3\n",
    "    ) AS min_data ON min_data.MIN_TEMP = WEATHER_DATA.MIN\n",
    "\"\"\")\n",
    "queried_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----+-------------------+\n",
      "|    STATION|            LOCATION|YEAR|      PRECIPITATION|\n",
      "+-----------+--------------------+----+-------------------+\n",
      "|72429793812|CINCINNATI MUNICI...|2018|0.15789041095890405|\n",
      "|99495199999|SEBASTIAN INLET S...|2015|                0.0|\n",
      "+-----------+--------------------+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.filter(csv_df.PRCP != 99.99).createOrReplaceTempView(\"WEATHER_DATA\")\n",
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        STATION,\n",
    "        LOCATION,\n",
    "        YEAR,\n",
    "        PRECIPITATION\n",
    "    FROM (\n",
    "        SELECT\n",
    "            WEATHER_DATA.STATION,\n",
    "            WEATHER_DATA.NAME AS LOCATION,\n",
    "            WEATHER_DATA.YEAR,\n",
    "            AVG(WEATHER_DATA.PRCP) AS PRECIPITATION,\n",
    "            ROW_NUMBER() OVER (PARTITION BY WEATHER_DATA.STATION ORDER BY AVG(WEATHER_DATA.PRCP) DESC, WEATHER_DATA.YEAR) AS ranked_order\n",
    "        FROM WEATHER_DATA\n",
    "        GROUP BY WEATHER_DATA.YEAR, WEATHER_DATA.STATION, WEATHER_DATA.NAME\n",
    "        ORDER BY WEATHER_DATA.YEAR, WEATHER_DATA.STATION\n",
    "    ) AS avg_prcps\n",
    "    WHERE avg_prcps.ranked_order = 1\n",
    "    ORDER BY STATION\n",
    "\"\"\")\n",
    "queried_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------+\n",
      "|    STATION|            LOCATION|MISSING_GUSTS|\n",
      "+-----------+--------------------+-------------+\n",
      "|72429793812|CINCINNATI MUNICI...|          137|\n",
      "|99495199999|SEBASTIAN INLET S...|          133|\n",
      "+-----------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        WEATHER_DATA.STATION,\n",
    "        WEATHER_DATA.NAME AS LOCATION,\n",
    "        COUNT(WEATHER_DATA.GUST) AS MISSING_GUSTS\n",
    "    FROM WEATHER_DATA\n",
    "    WHERE WEATHER_DATA.GUST = 999.9 AND WEATHER_DATA.YEAR = 2024\n",
    "    GROUP BY WEATHER_DATA.STATION, WEATHER_DATA.NAME\n",
    "    ORDER BY STATION\n",
    "\"\"\")\n",
    "queried_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+------+------+------------------+\n",
      "|MONTH|              MEAN|MEDIAN|  MODE|             STDEV|\n",
      "+-----+------------------+------+------+------------------+\n",
      "|    1| 37.94516129032259|  37.7|  24.7| 8.210097587321375|\n",
      "|    2|  36.5896551724138|  36.0|  30.8| 7.764168131721883|\n",
      "|    3|  49.0741935483871|  47.8|  53.2| 8.636642408457773|\n",
      "|    4|51.779999999999994|  51.1|  53.2| 7.190243389482725|\n",
      "|    5| 60.89032258064518|  63.7|  73.9| 9.163298280630869|\n",
      "|    6| 72.54666666666667| 73.95|  74.2| 4.817588147149521|\n",
      "|    7|              77.6|  77.9|  79.7| 2.299929872703694|\n",
      "|    8| 73.34516129032258|  73.7|  73.2| 3.431151288931137|\n",
      "|    9|              66.1| 66.15|  54.7|  6.99861891137577|\n",
      "|   10|55.193548387096776|  54.0|  59.4| 6.619274664671979|\n",
      "|   11|48.003333333333345|  47.7|  47.7| 6.711208700541371|\n",
      "|   12| 35.99354838709677|  35.2|  37.4|6.5347673396336425|\n",
      "+-----+------------------+------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        MONTH,\n",
    "        AVG(TEMP) AS MEAN,\n",
    "        MEDIAN(TEMP) AS MEDIAN,\n",
    "        MODE(TEMP) AS MODE,\n",
    "        STDDEV_POP(TEMP) AS STDEV\n",
    "    FROM WEATHER_DATA\n",
    "    WHERE STATION = 72429793812 AND YEAR = 2020\n",
    "    GROUP BY MONTH\n",
    "    ORDER BY MONTH\n",
    "\"\"\")\n",
    "queried_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "|      DATE|         WIND_CHILL|\n",
      "+----------+-------------------+\n",
      "|2017-01-07|-0.4140156367932173|\n",
      "|2017-12-31| 2.0339767075993116|\n",
      "|2017-12-27|  3.820645509123832|\n",
      "|2017-12-28|  4.533355269061226|\n",
      "|2017-01-06|  4.868933041653884|\n",
      "|2017-01-08|  7.929748208036862|\n",
      "|2017-12-25| 14.285113218297408|\n",
      "|2017-12-30| 14.539211253038193|\n",
      "|2017-01-05| 14.748861828163854|\n",
      "|2017-12-26| 15.688977805634499|\n",
      "+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df = csv_df.withColumn('WIND_CHILL', when((col('TEMP') < 50) & (col('WDSP') > 3), 35.74 + 0.6215 * col('TEMP') - 35.75 * col('WDSP')**0.16 + 0.4275 * col('TEMP') * col('WDSP')**0.16).otherwise(9999.9))\n",
    "csv_df.filter(csv_df.TEMP != 9999.9).filter(csv_df.WDSP != 999.9).createOrReplaceTempView(\"WEATHER_DATA\")\n",
    "\n",
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        DATE,\n",
    "        WIND_CHILL\n",
    "    FROM WEATHER_DATA\n",
    "    WHERE STATION = 72429793812 AND YEAR = 2017\n",
    "    ORDER BY WIND_CHILL, DATE\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "queried_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
