{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, month, when, concat_ws\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "spark = SparkSession.builder.master('local').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = []\n",
    "for data_year in range(2015, 2025):\n",
    "    file_path = f'data/{data_year}/72429793812.csv'\n",
    "    if os.path.exists(file_path):\n",
    "        input_files.append(file_path)\n",
    "    file_path = f'data/{data_year}/99495199999.csv'\n",
    "    if os.path.exists(file_path):\n",
    "        input_files.append(file_path)\n",
    "\n",
    "csv_df = spark.read.csv(input_files, sep=\",\", header=True)\n",
    "csv_df = csv_df.withColumn('YEAR', year(col('DATE')))\n",
    "csv_df = csv_df.withColumn('MONTH', month(col('DATE')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----+-----------+\n",
      "|    STATION|            LOCATION|YEAR|NUM_ENTRIES|\n",
      "+-----------+--------------------+----+-----------+\n",
      "|72429793812|CINCINNATI MUNICI...|2015|        365|\n",
      "|99495199999|SEBASTIAN INLET S...|2015|        355|\n",
      "|72429793812|CINCINNATI MUNICI...|2016|        366|\n",
      "|72429793812|CINCINNATI MUNICI...|2017|        365|\n",
      "|99495199999|SEBASTIAN INLET S...|2017|        283|\n",
      "|72429793812|CINCINNATI MUNICI...|2018|        365|\n",
      "|99495199999|SEBASTIAN INLET S...|2018|        363|\n",
      "|72429793812|CINCINNATI MUNICI...|2019|        365|\n",
      "|99495199999|SEBASTIAN INLET S...|2019|        345|\n",
      "|72429793812|CINCINNATI MUNICI...|2020|        366|\n",
      "|99495199999|SEBASTIAN INLET S...|2020|        365|\n",
      "|72429793812|CINCINNATI MUNICI...|2021|        365|\n",
      "|99495199999|SEBASTIAN INLET S...|2021|        104|\n",
      "|72429793812|CINCINNATI MUNICI...|2022|        365|\n",
      "|99495199999|SEBASTIAN INLET S...|2022|        259|\n",
      "|72429793812|CINCINNATI MUNICI...|2023|        365|\n",
      "|99495199999|SEBASTIAN INLET S...|2023|        276|\n",
      "|72429793812|CINCINNATI MUNICI...|2024|        366|\n",
      "|99495199999|SEBASTIAN INLET S...|2024|        133|\n",
      "+-----------+--------------------+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.createOrReplaceTempView(\"WEATHER_DATA\")\n",
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        WEATHER_DATA.STATION,\n",
    "        WEATHER_DATA.NAME AS LOCATION,\n",
    "        WEATHER_DATA.YEAR,\n",
    "        COUNT(WEATHER_DATA.TEMP) AS NUM_ENTRIES\n",
    "    FROM WEATHER_DATA\n",
    "    GROUP BY WEATHER_DATA.YEAR, WEATHER_DATA.NAME, WEATHER_DATA.STATION\n",
    "    ORDER BY WEATHER_DATA.YEAR, WEATHER_DATA.STATION\n",
    "\"\"\")\n",
    "queried_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+--------+\n",
      "|    STATION|            LOCATION|      DATE|MAX_TEMP|\n",
      "+-----------+--------------------+----------+--------+\n",
      "|72429793812|CINCINNATI MUNICI...|2015-06-12|    91.9|\n",
      "|72429793812|CINCINNATI MUNICI...|2016-07-24|    93.9|\n",
      "|72429793812|CINCINNATI MUNICI...|2017-07-22|    91.9|\n",
      "|72429793812|CINCINNATI MUNICI...|2018-07-04|    96.1|\n",
      "|72429793812|CINCINNATI MUNICI...|2019-09-30|    95.0|\n",
      "|72429793812|CINCINNATI MUNICI...|2020-07-05|    93.9|\n",
      "|72429793812|CINCINNATI MUNICI...|2021-08-12|    95.0|\n",
      "|72429793812|CINCINNATI MUNICI...|2022-06-14|    96.1|\n",
      "|72429793812|CINCINNATI MUNICI...|2023-08-23|    96.1|\n",
      "|72429793812|CINCINNATI MUNICI...|2024-08-30|   100.9|\n",
      "+-----------+--------------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.filter(csv_df.MAX != 9999.9).createOrReplaceTempView(\"WEATHER_DATA\")\n",
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        STATION,\n",
    "        LOCATION,\n",
    "        DATE,\n",
    "        MAX_TEMP\n",
    "    FROM (\n",
    "        SELECT\n",
    "            WEATHER_DATA.STATION,\n",
    "            WEATHER_DATA.NAME AS LOCATION,\n",
    "            WEATHER_DATA.DATE,\n",
    "            WEATHER_DATA.MAX AS MAX_TEMP,\n",
    "            ROW_NUMBER() OVER (PARTITION BY WEATHER_DATA.YEAR ORDER BY WEATHER_DATA.MAX DESC) AS ranked_order\n",
    "        FROM WEATHER_DATA\n",
    "    ) AS max_temps\n",
    "    WHERE max_temps.ranked_order = 1\n",
    "\"\"\")\n",
    "queried_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+--------+\n",
      "|    STATION|            LOCATION|      DATE|MIN_TEMP|\n",
      "+-----------+--------------------+----------+--------+\n",
      "|72429793812|CINCINNATI MUNICI...|2015-03-06|     3.2|\n",
      "+-----------+--------------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.filter(csv_df.MIN != 9999.9).createOrReplaceTempView(\"WEATHER_DATA\")\n",
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        STATION,\n",
    "        NAME AS LOCATION,\n",
    "        DATE,\n",
    "        MIN AS MIN_TEMP\n",
    "    FROM WEATHER_DATA\n",
    "    INNER JOIN (\n",
    "        SELECT\n",
    "            MIN(MIN) AS MIN_TEMP\n",
    "        FROM WEATHER_DATA\n",
    "        WHERE MONTH = 3\n",
    "    ) AS min_data ON min_data.MIN_TEMP = WEATHER_DATA.MIN\n",
    "\"\"\")\n",
    "queried_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----+-------------------+\n",
      "|    STATION|            LOCATION|YEAR|      PRECIPITATION|\n",
      "+-----------+--------------------+----+-------------------+\n",
      "|72429793812|CINCINNATI MUNICI...|2018|0.15789041095890405|\n",
      "|99495199999|SEBASTIAN INLET S...|2015|                0.0|\n",
      "+-----------+--------------------+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.filter(csv_df.PRCP != 99.99).createOrReplaceTempView(\"WEATHER_DATA\")\n",
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        STATION,\n",
    "        LOCATION,\n",
    "        YEAR,\n",
    "        PRECIPITATION\n",
    "    FROM (\n",
    "        SELECT\n",
    "            WEATHER_DATA.STATION,\n",
    "            WEATHER_DATA.NAME AS LOCATION,\n",
    "            WEATHER_DATA.YEAR,\n",
    "            AVG(WEATHER_DATA.PRCP) AS PRECIPITATION,\n",
    "            ROW_NUMBER() OVER (PARTITION BY WEATHER_DATA.STATION ORDER BY AVG(WEATHER_DATA.PRCP) DESC, WEATHER_DATA.YEAR) AS ranked_order\n",
    "        FROM WEATHER_DATA\n",
    "        GROUP BY WEATHER_DATA.YEAR, WEATHER_DATA.STATION, WEATHER_DATA.NAME\n",
    "        ORDER BY WEATHER_DATA.YEAR, WEATHER_DATA.STATION\n",
    "    ) AS avg_prcps\n",
    "    WHERE avg_prcps.ranked_order = 1\n",
    "    ORDER BY STATION\n",
    "\"\"\")\n",
    "queried_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+---------------------+\n",
      "|    STATION|            LOCATION|PERCENT_MISSING_GUSTS|\n",
      "+-----------+--------------------+---------------------+\n",
      "|72429793812|CINCINNATI MUNICI...|    39.14285714285714|\n",
      "|99495199999|SEBASTIAN INLET S...|                100.0|\n",
      "+-----------+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        WEATHER_DATA.STATION,\n",
    "        WEATHER_DATA.NAME AS LOCATION,\n",
    "        (SUM(\n",
    "            CASE\n",
    "                WHEN WEATHER_DATA.GUST = 999.9 THEN 1\n",
    "                ELSE 0\n",
    "            END\n",
    "        ) / COUNT(*)) * 100 AS PERCENT_MISSING_GUSTS\n",
    "    FROM WEATHER_DATA\n",
    "    WHERE WEATHER_DATA.YEAR = 2024\n",
    "    GROUP BY WEATHER_DATA.STATION, WEATHER_DATA.NAME\n",
    "    ORDER BY STATION\n",
    "\"\"\")\n",
    "queried_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+------+------+------------------+\n",
      "|MONTH|              MEAN|MEDIAN|  MODE|             STDEV|\n",
      "+-----+------------------+------+------+------------------+\n",
      "|    1| 37.94516129032259|  37.7|  24.7| 8.210097587321375|\n",
      "|    2|  36.5896551724138|  36.0|  30.8| 7.764168131721883|\n",
      "|    3|  49.0741935483871|  47.8|  53.2| 8.636642408457773|\n",
      "|    4|51.779999999999994|  51.1|  53.2| 7.190243389482725|\n",
      "|    5| 60.89032258064518|  63.7|  73.9| 9.163298280630869|\n",
      "|    6| 72.54666666666667| 73.95|  74.2| 4.817588147149521|\n",
      "|    7|              77.6|  77.9|  79.7| 2.299929872703694|\n",
      "|    8| 73.34516129032258|  73.7|  73.2| 3.431151288931137|\n",
      "|    9|              66.1| 66.15|  54.7|  6.99861891137577|\n",
      "|   10|55.193548387096776|  54.0|  59.4| 6.619274664671979|\n",
      "|   11|48.003333333333345|  47.7|  47.7| 6.711208700541371|\n",
      "|   12| 35.99354838709677|  35.2|  37.4|6.5347673396336425|\n",
      "+-----+------------------+------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        MONTH,\n",
    "        AVG(TEMP) AS MEAN,\n",
    "        MEDIAN(TEMP) AS MEDIAN,\n",
    "        MODE(TEMP) AS MODE,\n",
    "        STDDEV_POP(TEMP) AS STDEV\n",
    "    FROM WEATHER_DATA\n",
    "    WHERE STATION = 72429793812 AND YEAR = 2020\n",
    "    GROUP BY MONTH\n",
    "    ORDER BY MONTH\n",
    "\"\"\")\n",
    "queried_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "|      DATE|         WIND_CHILL|\n",
      "+----------+-------------------+\n",
      "|2017-01-07|-0.4140156367932173|\n",
      "|2017-12-31| 2.0339767075993116|\n",
      "|2017-12-27|  3.820645509123832|\n",
      "|2017-12-28|  4.533355269061226|\n",
      "|2017-01-06|  4.868933041653884|\n",
      "|2017-01-08|  7.929748208036862|\n",
      "|2017-12-25| 14.285113218297408|\n",
      "|2017-12-30| 14.539211253038193|\n",
      "|2017-01-05| 14.748861828163854|\n",
      "|2017-12-26| 15.688977805634499|\n",
      "+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df = csv_df.withColumn('WIND_CHILL', when((col('TEMP') < 50) & (col('WDSP') > 3), 35.74 + 0.6215 * col('TEMP') - 35.75 * col('WDSP')**0.16 + 0.4275 * col('TEMP') * col('WDSP')**0.16).otherwise(9999.9))\n",
    "csv_df.filter(csv_df.TEMP != 9999.9).filter(csv_df.WDSP != 999.9).createOrReplaceTempView(\"WEATHER_DATA\")\n",
    "\n",
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        DATE,\n",
    "        WIND_CHILL\n",
    "    FROM WEATHER_DATA\n",
    "    WHERE STATION = 72429793812 AND YEAR = 2017\n",
    "    ORDER BY WIND_CHILL, DATE\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "queried_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------+\n",
      "|STATION|LOCATION|DAYS_EXTREME|\n",
      "+-------+--------+------------+\n",
      "+-------+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        STATION,\n",
    "        NAME AS LOCATION,\n",
    "        COUNT(FRSHTT) AS DAYS_EXTREME\n",
    "    FROM WEATHER_DATA\n",
    "    WHERE FRSHTT <> 0 AND STATION = 99495199999\n",
    "    GROUP BY STATION, LOCATION\n",
    "\"\"\")\n",
    "queried_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date | Temperature\n",
      "11/1/2024 | 41.76 F\n",
      "11/2/2024 | 40.96 F\n",
      "11/3/2024 | 45.86 F\n",
      "11/4/2024 | 57.26 F\n",
      "11/5/2024 | 53.86 F\n",
      "11/6/2024 | 53.16 F\n",
      "11/7/2024 | 70.06 F\n",
      "11/8/2024 | 61.76 F\n",
      "11/9/2024 | 68.46 F\n",
      "11/10/2024 | 56.76 F\n",
      "11/11/2024 | 46.46 F\n",
      "11/12/2024 | 45.66 F\n",
      "11/13/2024 | 46.96 F\n",
      "11/14/2024 | 44.66 F\n",
      "11/15/2024 | 46.96 F\n",
      "11/16/2024 | 51.46 F\n",
      "11/17/2024 | 60.06 F\n",
      "11/18/2024 | 49.66 F\n",
      "11/19/2024 | 43.16 F\n",
      "11/20/2024 | 44.16 F\n",
      "11/21/2024 | 52.76 F\n",
      "11/22/2024 | 48.76 F\n",
      "11/23/2024 | 42.86 F\n",
      "11/24/2024 | 39.46 F\n",
      "11/25/2024 | 39.06 F\n",
      "11/26/2024 | 42.56 F\n",
      "11/27/2024 | 39.16 F\n",
      "11/28/2024 | 30.26 F\n",
      "11/29/2024 | 30.96 F\n",
      "11/30/2024 | 41.56 F\n",
      "12/1/2024 | 52.06 F\n",
      "12/2/2024 | 55.46 F\n",
      "12/3/2024 | 51.66 F\n",
      "12/4/2024 | 42.06 F\n",
      "12/5/2024 | 42.46 F\n",
      "12/6/2024 | 43.86 F\n",
      "12/7/2024 | 41.86 F\n",
      "12/8/2024 | 51.56 F\n",
      "12/9/2024 | 60.26 F\n",
      "12/10/2024 | 46.66 F\n",
      "12/11/2024 | 38.86 F\n",
      "12/12/2024 | 36.96 F\n",
      "12/13/2024 | 35.96 F\n",
      "12/14/2024 | 35.56 F\n",
      "12/15/2024 | 38.26 F\n",
      "12/16/2024 | 40.96 F\n",
      "12/17/2024 | 52.16 F\n",
      "12/18/2024 | 42.96 F\n",
      "12/19/2024 | 32.76 F\n",
      "12/20/2024 | 34.16 F\n",
      "12/21/2024 | 37.96 F\n",
      "12/22/2024 | 41.96 F\n",
      "12/23/2024 | 47.46 F\n",
      "12/24/2024 | 53.56 F\n",
      "12/25/2024 | 48.16 F\n",
      "12/26/2024 | 57.86 F\n",
      "12/27/2024 | 47.46 F\n",
      "12/28/2024 | 41.56 F\n",
      "12/29/2024 | 40.86 F\n",
      "12/30/2024 | 41.36 F\n",
      "12/31/2024 | 42.26 F\n"
     ]
    }
   ],
   "source": [
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        TEMP\n",
    "    FROM WEATHER_DATA\n",
    "    WHERE STATION = 72429793812 AND MONTH = 11 AND YEAR IN (2022, 2023)\n",
    "    ORDER BY DATE\n",
    "\"\"\").collect()\n",
    "november_temps = [float(row.__getitem__('TEMP')) for row in queried_data]\n",
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        TEMP\n",
    "    FROM WEATHER_DATA\n",
    "    WHERE STATION = 72429793812 AND MONTH = 12 AND YEAR IN (2022, 2023)\n",
    "    ORDER BY DATE\n",
    "\"\"\").collect()\n",
    "december_temps = [float(row.__getitem__('TEMP')) for row in queried_data]\n",
    "nov_22 = november_temps[0:int(len(november_temps)/2)]\n",
    "nov_23 = november_temps[int(len(november_temps)/2):]\n",
    "dec_22 = december_temps[0:int(len(december_temps)/2)]\n",
    "dec_23 = december_temps[int(len(december_temps)/2):]\n",
    "\n",
    "sum_yearly_diffs = 0\n",
    "for i in range(len(dec_22)):\n",
    "    if i < len(nov_22):\n",
    "        diff = nov_23[i] - nov_22[i]\n",
    "        sum_yearly_diffs = sum_yearly_diffs + diff\n",
    "    diff = dec_23[i] - dec_22[i]\n",
    "    sum_yearly_diffs = sum_yearly_diffs + diff\n",
    "\n",
    "avg_diff = sum_yearly_diffs/(len(nov_22) + len(dec_22))\n",
    "\n",
    "predicted_data = []\n",
    "for i in range(len(nov_23)):\n",
    "    predicted_data.append((f\"11/{i + 1}/2024\", nov_23[i] + avg_diff))\n",
    "for i in range(len(dec_23)):\n",
    "    predicted_data.append((f\"12/{i + 1}/2024\", dec_23[i] + avg_diff))\n",
    "\n",
    "print('Date | Temperature')\n",
    "for predicted_temp in predicted_data:\n",
    "    print(f'{predicted_temp[0]} | {round(predicted_temp[1], 2)} F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      DATE|  TEMP|\n",
      "+----------+------+\n",
      "|2024-11-01|  55.3|\n",
      "|2024-11-02|  46.0|\n",
      "|2024-11-03|  50.7|\n",
      "|2024-11-04|  65.4|\n",
      "|2024-11-05|  69.9|\n",
      "|2024-11-06|  68.8|\n",
      "|2024-11-07|  60.5|\n",
      "|2024-11-08|  49.6|\n",
      "|2024-11-09|  49.1|\n",
      "|2024-11-10|  58.5|\n",
      "|2024-11-11|  57.0|\n",
      "|2024-11-12|  47.0|\n",
      "|2024-11-13|  44.4|\n",
      "|2024-11-14|  53.8|\n",
      "|2024-11-15|  52.2|\n",
      "|2024-11-16|  50.6|\n",
      "|2024-11-17|  46.3|\n",
      "|2024-11-18|  57.4|\n",
      "|2024-11-19|  59.7|\n",
      "|2024-11-20|  52.8|\n",
      "|2024-11-21|  38.2|\n",
      "|2024-11-22|  37.9|\n",
      "|2024-11-23|  44.9|\n",
      "|2024-11-24|  46.2|\n",
      "|2024-11-25|  51.2|\n",
      "|2024-11-26|  46.6|\n",
      "|2024-11-27|  41.5|\n",
      "|2024-11-28|  41.4|\n",
      "|2024-11-29|  34.1|\n",
      "|2024-11-30|  27.0|\n",
      "|2024-12-01|  31.1|\n",
      "|2024-12-02|  26.3|\n",
      "|2024-12-03|  25.9|\n",
      "|2024-12-04|  32.6|\n",
      "|2024-12-05|  29.0|\n",
      "|2024-12-06|  23.6|\n",
      "|2024-12-07|  31.0|\n",
      "|2024-12-08|  47.6|\n",
      "|2024-12-09|  54.4|\n",
      "|2024-12-10|  48.0|\n",
      "|2024-12-11|  35.6|\n",
      "|2024-12-12|  28.5|\n",
      "|2024-12-13|  27.6|\n",
      "|2024-12-14|  34.2|\n",
      "|2024-12-15|  46.2|\n",
      "|2024-12-16|  52.9|\n",
      "|2024-12-17|  46.8|\n",
      "|2024-12-18|  38.8|\n",
      "|2024-12-19|  38.1|\n",
      "|2024-12-20|  36.1|\n",
      "|2024-12-21|  32.1|\n",
      "|2024-12-22|  25.8|\n",
      "|2024-12-23|  33.8|\n",
      "|2024-12-24|  46.2|\n",
      "|2024-12-25|  44.5|\n",
      "|2024-12-26|  46.4|\n",
      "|2024-12-27|  44.9|\n",
      "|2024-12-28|  55.9|\n",
      "|2024-12-29|  56.5|\n",
      "|2024-12-30|  46.4|\n",
      "|2024-12-31|  47.4|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queried_data = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        DATE,\n",
    "        TEMP\n",
    "    FROM WEATHER_DATA\n",
    "    WHERE STATION = 72429793812 AND YEAR = 2024 AND MONTH IN (11, 12)\n",
    "    ORDER BY DATE\n",
    "\"\"\")\n",
    "queried_data.show(n=queried_data.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
